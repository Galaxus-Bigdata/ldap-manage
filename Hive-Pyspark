from pyspark.sql import SparkSession

# Initialize a Spark session
spark = SparkSession.builder \
    .appName("HiveTableLocation") \
    .enableHiveSupport() \
    .getOrCreate()

# Set the Hive database and table name
database_name = "your_database_name"
table_name = "your_table_name"

# Use Spark SQL to get the table location
location_query = f"DESCRIBE FORMATTED {database_name}.{table_name}"
table_location = spark.sql(location_query)

# Filter the result to get the location
table_location = table_location.filter(table_location.col_name == "Location").select("data_type").collect()[0][0]

# Print the table location
print(f"Location of {database_name}.{table_name} is: {table_location}")

# Stop the Spark session
spark.stop()
